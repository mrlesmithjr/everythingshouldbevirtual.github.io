---
layout: post
title: ELK Stack Setup For Business
date: 
type: post
published: false
status: draft
categories: []
tags: []
meta:
  _edit_last: '11'
  snap_MYURL: ''
  snapEdIT: '1'
  snapDL: s:102:"a:1:{i:0;a:3:{s:4:"doDL";s:1:"1";s:11:"SNAPformatT";s:7:"%TITLE%";s:10:"SNAPformat";s:9:"%EXCERPT%";}}";
  snapFB: s:253:"a:1:{i:0;a:8:{s:4:"doFB";s:1:"1";s:8:"postType";s:1:"A";s:10:"AttachPost";s:1:"1";s:10:"SNAPformat";s:51:"New
    post (%TITLE%) has been published on %SITENAME%";s:9:"isAutoImg";s:1:"A";s:8:"imgToUse";s:0:"";s:9:"isAutoURL";s:1:"A";s:8:"urlToUse";s:0:"";}}";
  snapLI: s:246:"a:1:{i:0;a:8:{s:4:"doLI";s:1:"1";s:10:"AttachPost";s:1:"1";s:10:"SNAPformat";s:41:"New
    post has been published on %SITENAME%";s:11:"SNAPformatT";s:0:"";s:9:"isAutoImg";s:1:"A";s:8:"imgToUse";s:0:"";s:9:"isAutoURL";s:1:"A";s:8:"urlToUse";s:0:"";}}";
  snapSU: s:119:"a:1:{i:0;a:4:{s:4:"doSU";s:1:"1";s:7:"apSUCat";s:2:"IT";s:4:"nsfw";s:1:"0";s:10:"SNAPformat";s:16:"%TITLE%
    - %TEXT%";}}";
  snapTW: 's:172:"a:1:{i:0;a:5:{s:4:"doTW";s:1:"1";s:10:"SNAPformat";s:42:"%TITLE%
    - %URL% #everythingshouldbevirtual";s:8:"attchImg";s:1:"0";s:9:"isAutoImg";s:1:"A";s:8:"imgToUse";s:0:"";}}";'
  _s2mail: 'yes'
author:
  login: larry.e.smith.jr
  email: larry.e.smith.jr@gmail.com
  display_name: mrlesmithjr
  first_name: Larry
  last_name: Smith
---
<p>In this post I will be going over how to setup a complete ELK (Elasticsearch, Logstash and Kibana) stack with clustered elasticsearch and all ELK components load balanced using HAProxy. I will be making many changes to this post as this solution expands. I will be commenting out previous parts of this post that are being updated. This will allow for some who have implemented during the progress of this post to still have a reference. Eventually I will circle back around and remove out the commented sections.</p>
<p>I will be setting up a total of <del>four</del> <del>six</del> eight servers (2-HAProxy, 2-ELK brokers, 2-ELK Processors and 2-Elasticsearch master/data nodes) in this setup however you can scale the ELK stack by adding additional nodes <del> identical to logstash-1/logstash-2</del> in any part of the stack that you would like. You will only need to make the configuration changes to<del> for logstash processing and Kibana web interfaces and</del> adding the additional node info to the HAProxy configuration files to load balance. You can also scale the Elasticsearch Master/Data nodes by building out addtional nodes and they will join the cluster automatically.</p>
<p><strong>Acronyms throughout article</strong><br />
ELK - Elasticsearch Logstash Kibana<br />
ES - Elasticsearch</p>
<hr />
<p><strong>Requirements:</strong><br />
In order for all logstash-elasticsearch clustering to work correctly all HAProxy nodes and ELK nodes should be on the same subnet (If not you will need to configure <a title="Highly Available ELK (Elasticsearch, Logstash and Kibana) Unicast Mode" href="http://everythingshouldbevirtual.com/highly-available-elk-elasticsearch-logstash-kibana-unicast-mode">unicast </a>mode for Elasticsearch as multicast is enabled using these scripts).<br />
Two Ubuntu (12.04LTS/14.04LTS) HAProxy nodes<del> with two NICS each</del>. <em>(1vCPU and 512MB memory will work)</em><br />
<del>Two or more Ubuntu (12.04LTS/14.04LTS) nodes to install the ELK stack frontends. <em>(2vCPU and 2GB memory will work)</em></del><br />
Two Ubuntu (12.04LTS/14.04LTS) ELK-Brokers <em>(1vCPU and 1GB memory will work)</em><br />
Two Ubuntu (12.04LTS/14.04LTS) ELK-Processors <em>(4vCPU and 2GB memory will work)</em><br />
Two Ubuntu (12.04LTS/14.04LTS) nodes to install the ES Master/Data nodes. <em>(2vCPU and 4GB of memory will work)</em></p>
<p>IP Addresses and hostnames required to set all of this up. (Change to fit your environment.)<br />
DNS A Record: <strong><em>logstash</em> </strong>(with the LB VIP address)<br />
DNS A Records for each node. (DHCP will work but certain pieces of the setup may break initially if every node is not online and not in DNS; so static is preferred)</p>
<p><del>(If you use something other than this name update in each location that logstash is configured for. I will be providing a script to do this in the near future.)</del> Each script will prompt for IPs and hostnames for relevant parts of the setup; this will allow you to use your own naming throughout the stack.</p>
<p>LB VIP <em>10.0.101.60</em><br />
LB Hostname <em>logstash</em><br />
<del>haproxy-1 10.0.101.61</del><br />
<del> haproxy-2 10.0.101.62</del><br />
<del> logstash-1 10.0.101.185</del><br />
<del datetime="2014-06-10T01:35:40+00:00">logstash-1 172.16.0.1 (Cluster Heartbeat)</del><br />
<del>logstash-2 10.0.101.180</del><br />
<del datetime="2014-06-10T01:35:40+00:00">logstash-2 172.16.0.2 (Cluster Heartbeat)</del><br />
<del>es-1 10.0.101.131</del><br />
<del> es-2 10.0.101.179</del><br />
elk-haproxy-1 <em>10.0.101.61</em><br />
elk-haproxy-2 <em>10.0.101.62</em><br />
elk-broker-1 <em>10.0.101.63</em><br />
elk-broker-2 <em>10.0.101.64</em><br />
elk-processor-1 <em>10.0.101.65</em><br />
elk-processor-2 <em>10.0.101.66</em><br />
elk-es-1 <em>10.0.101.67</em><br />
elk-es-2 <em>10.0.101.68</em></p>
<p><del>If you decide to use different node names than the above list then you will need to make sure to make changes to the configurations to reflect these changes.</del> The scripts take care of this now.</p>
<hr />
<p><strong>ELK-HAProxy Nodes (elk-haproxy-1, elk-haproxy-2):</strong><br />
Setup both HAProxy nodes identical all the way down to the ELK stack setup section. The below instructions which have been crossed out are no longer valid but will remain in the off chance that you would like to use heartbeat instead of keepalived or did not use the install scripts for your cluster setup.</p>
<p>So to setup your Haproxy nodes I have created a script to do the setup of this for you. So this will be extremely simple now. So in order to do this make sure that you have your two ELK-HAProxy nodes setup and ready to go. (Remember to have all IP's and DNS records for all eight of your servers available as well as the VIP IP and hostname)</p>
<p>On ELK-HAProxy node #1 do the following.</p>
<pre>sudo apt-get install git
cd ~
git clone https://github.com/mrlesmithjr/Logstash_Kibana3
chmod +x Logstash_Kibana3/Cluster/ELK-HAProxy-Node.sh
sudo ./Logstash_Kibana3/Cluster/ELK-HAProxy-Node.sh</pre>
<p>Follow all prompts on the screen and setup will complete. Once this has been completed proceed to ELK-HAProxy node #2 and run the same above commands.<br />
So once you have both ELK-HAProxy nodes setup you can proceed to installing your ELK-ES nodes.</p>
<p><del>First thing we need to do is install all of the packages needed.</del><br />
<del datetime="2014-06-10T01:35:40+00:00">sudo apt-get install haproxy heartbeat watchdog</del><br />
<del datetime="2014-06-10T01:35:40+00:00">Now we will need to configure networking on each nodes as follows. (Again modify to fit your environment.)</del></p>
<pre><del>sudo apt-get install haproxy keepalived</del></pre>
<p><del datetime="2014-06-10T01:35:40+00:00"><strong>HAProxy-1 (Primary)</strong></del><br />
<del datetime="2014-06-10T01:35:40+00:00">sudo nano /etc/network/interfaces<br />
Overwrite the contents with the code from below.<br />
https://gist.github.com/mrlesmithjr/1a52e824f22ced8e6758</del></p>
<p><del datetime="2014-06-10T01:35:40+00:00"><strong>HAProxy-2 (Failover)</strong></del><br />
<del datetime="2014-06-10T01:35:40+00:00">sudo nano /etc/network/interfaces<br />
Overwrite the contents with the code from below.<br />
https://gist.github.com/mrlesmithjr/c8d756fb927af7f0927d</del></p>
<p><del>We need to allow an interface to be brought online that is not part of the <em>/etc/network/interfaces</em> configuration so we need to run the following. This will allow all of our VIP's to come up.</del></p>
<pre><del>echo "net.ipv4.ip_nonlocal_bind=1" &gt;&gt; /etc/sysctl.conf</del></pre>
<p><del>Verify that the above setting has been set by running the following on each node. You should get back the following <span style="color: #141412;">‘</span><em style="color: #141412;">net.ipv4.ip_nonlocal_bind = 1</em><span style="color: #141412;">‘</span></del></p>
<pre><del>sysctl -p</del></pre>
<p><del datetime="2014-06-10T01:35:40+00:00">Now you will need to restart networking on each node or reboot for the IP settings from above to be set.<br />
sudo service networking restart<br />
Now we are ready to configure our heartbeat service on each node. We will do that by setting up the following configuration files on each node.<br />
sudo nano /etc/ha.d/ha.cf<br />
Copy the following into ha.cf file.</del></p>
<p><del datetime="2014-06-10T01:35:40+00:00">https://gist.github.com/mrlesmithjr/1e9a5072b668fb5ea839<br />
sudo nano /etc/ha.d/authkeys<br />
Copy the following into authkeys (change password to something else).<br />
auth 3<br />
1 crc<br />
2 sha1 password<br />
3 md5 password</del></p>
<p><del datetime="2014-06-10T01:35:40+00:00">Now change the permissions of the authkeys as follows.<br />
sudo chmod 600 /etc/ha.d/authkeys<br />
Now we will create the haresources file to complete the heartbeat service setup.<br />
sudo nano /etc/ha.d/haresources<br />
Copy the following into haresources.<br />
haproxy-1 IPaddr::10.0.101.60/24/eth0 logstash</del></p>
<p><del>Now we need to configure the keepalived cluster service. All that we need to do is create <em>/etc/keepalived/keepalived.conf</em></del></p>
<pre><del>sudo nano /etc/keepalived/keepalived.conf</del></pre>
<p><del>And copy the contents from below and save the file. Make sure to modify the IP addresses to match your environment.</del><br />
<del> https://gist.github.com/mrlesmithjr/9b11490f45c602726f81</del></p>
<p><del>Now you need to start the <em>keepalived</em> service</del></p>
<pre><del>sudo service keepalived start</del></pre>
<p><del>You can check and make sure that all of your VIP's came up by running the following. A normal ifconfig will not show them.</del></p>
<pre><del>sudo ip a | grep -e inet.*eth0</del></pre>
<p>You should see something similar to below.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-09_22-04-58.png"><img class="alignnone size-medium wp-image-2881" src="{{ site.baseurl }}/assets/2014-06-09_22-04-58-300x66.png" alt="2014-06-09_22-04-58" width="300" height="66" /></a></p>
<p><del>Now we are ready to setup HAProxy for our ELK stack. The final piece of our setup for frontend load balancer cluster.</del></p>
<pre><del>sudo nano /etc/haproxy/haproxy.cfg</del></pre>
<p><del>Replace all contents in haproxy.cfg with the following code.</del><br />
<del> https://gist.github.com/mrlesmithjr/5ee958df9c9ad941ac2d</del><br />
<del> Now we need to set HAProxy to enabled so it will start.</del></p>
<pre><del>sudo nano /etc/default/haproxy</del></pre>
<p><del>Change</del></p>
<pre><del>ENABLED=0</del></pre>
<p><del>to</del></p>
<pre><del>ENABLED=1</del></pre>
<p><del>Now we should be able to start HAProxy up.</del></p>
<pre><del>sudo service haproxy start</del></pre>
<p>If you see errors similar to below these can be ignored.</p>
<pre>[WARNING] 153/132650 (4054) : config : 'option httplog' not usable with proxy 'logstash-syslog-514' (needs 'mode http'). Falling back to 'option tcplog'.
[WARNING] 153/132650 (4054) : config : 'option httplog' not usable with proxy 'logstash-syslog-1514' (needs 'mode http'). Falling back to 'option tcplog'.
[WARNING] 153/132650 (4054) : config : 'option httplog' not usable with proxy 'logstash-eventlog' (needs 'mode http'). Falling back to 'option tcplog'.
[WARNING] 153/132650 (4054) : config : 'option httplog' not usable with proxy 'logstash-iis' (needs 'mode http'). Falling back to 'option tcplog'.
[WARNING] 153/132650 (4054) : config : 'option httplog' not usable with proxy 'logstash-redis' (needs 'mode http'). Falling back to 'option tcplog'.
[WARNING] 153/132650 (4054) : config : 'option httplog' not usable with proxy 'elasticsearch' (needs 'mode http'). Falling back to 'option tcplog'.
[ OK ]</pre>
<p><del>Now one last thing to do based on the fact that HAProxy cannot load balance UDP ports and not all network devices have the option to send their syslog data to a TCP port. We will install an instance of Logstash and setup rsyslog forwarding on each HAProxy node. This instance will only listen for syslog on the standard UDP/514 port, do some filtering and join the logstash-elasticsearch cluster as a client and output to this cluster. be configured to monitor the nginx logs and forward them back to the logstash cluster using redis. We will be configuring rsyslog to listen on UDP/514 and forward to the logstash cluster over TCP/514. I have made this extremely easy by running a script.</del> <del><strong>However do not run this until after you have setup your ELK stack nodes below. If you do set this up prior to building out your ELK nodes then you will need to restart the logstash service on each of your haproxy nodes.</strong></del><br />
<del>If for some reason you need to restart the logstash service you can do so by running.</del></p>
<pre><del>sudo service logstash restart</del></pre>
<p><del>So let's setup our logstash instance and configure rsyslog forwarding. To do so run the following commands in a terminal session on each of your HAProxy nodes.</del></p>
<pre><del>sudo apt-get install git
cd ~
git clone https://github.com/mrlesmithjr/Logstash_Kibana3
chmod +x ./Logstash_Kibana3/Cluster_Setup/Logstash-HAProxy-Node.sh
sudo ./Logstash_Kibana3/Cluster_Setup/Logstash-HAProxy-Node.sh
</del></pre>
<p><del datetime="2014-06-10T01:35:40+00:00">If you copied the haresources file exactly from above then Logstash will only be running on the active cluster node and will start on the failover node when a failover occurs.</del></p>
<p><del>Now HAProxy node1 is complete make sure to do all of the above on your HAProxy node2 and make sure to change the priority as noted in the <em>keepalived.conf</em> file. Once you have completed HAProxy node2 continue onto the next section of setting up your ELK stack. You could also clone the first node to create the second node but if you do; make sure to make the proper change in keepalived.conf and haproxy.cfg as above.</del></p>
<hr />
<p><strong>ELK-ES (Elasticsearch Master/Data Nodes (elk-es-1, elk-es-2):</strong><br />
Now we will be setting up our two nodes to build our Elasticsearch cluster and again I have a script to do this. These nodes will only be Master/Data nodes. They will not be doing any logstash processing. They will purely be used to maintain the cluster and provide redundancy. <del>These nodes will not be exposed to the HAProxy Load Balancers; Only our ELK nodes below will be.</del> These nodes will process all of the data that our <del>frontend ELK nodes</del> elk-processor nodes send back to be ingested, indexed and etc. For now we will only be setting up two ES Master/Data nodes; however you can build out as many as you like and use this same script each time for each additional node (If you add more than two you will want to adjust the following parameter in /etc/elasticsearch/elasticsearch.yml to ensure you do not experience a split-brain ES cluster. You will set the value to n/2+1 where n=number of nodes. If you are only using 2 nodes leave this value unset or =1. So for example if you had 3 nodes the value would be 2 (3/2+1=2) whereas if you had 6 nodes it would be (6/2+1=4)). Just make sure that every node-name is unique and has a DNS record associated with it. (The following settings are added for you using the script but are commented out.)</p>
<p><em>discovery.zen.minimum_master_nodes: 2</em></p>
<p>So let's get these nodes up and running.<br />
On your new ES nodes run the following script on each to get them running.</p>
<pre><del>sudo apt-get install git
cd ~
git clone https://github.com/mrlesmithjr/Logstash_Kibana3
chmod +x ./Logstash_Kibana3/Cluster_Setup/Logstash-ES-Cluster-Master-data-node.sh
sudo ./Logstash_Kibana3/Cluster_Setup/Logstash-ES-Cluster-Master-data-node.sh
</del></pre>
<pre>sudo apt-get install git
cd ~
git clone https://github.com/mrlesmithjr/Logstash_Kibana3
chmod +x ./Logstash_Kibana3/Cluster/ELK-ES-Node.sh
sudo ./Logstash_Kibana3/Cluster/ELK-ES-Node.sh</pre>
<p>Once these are up and running your new ES cluster (logstash-cluster) should be ready to go. However you will want to modify your Java Heap Size to 50% of the installed memory. So if you installed per the requirements you will want to adjust the ES_HEAP_SIZE to 2g because by default it will be at 1g. And it is commented out by default. <em>(This is now enabled using the script; however it is assumed that you installed on a node with 4GB+ memory)</em></p>
<pre><del>sudo nano /etc/init.d/elasticsearch</del></pre>
<p><del>change</del></p>
<pre><del>#ES_HEAP_SIZE=1g</del></pre>
<p><del>to</del></p>
<pre><del>ES_HEAP_SIZE=2g</del></pre>
<p><del>Now proceed onto setting up the frontend ELK nodes.</del></p>
<p>Now proceed onto setting up your ELK-Broker nodes.</p>
<hr />
<p>&nbsp;</p>
<p><strong>ELK-Broker Nodes (elk-broker-1, elk-broker-2)</strong></p>
<p>Now let's setup our ELK-Broker nodes. These nodes are going to be used for collecting all of our logs initially (cached) using Redis. These nodes will be what our ELK-HAProxy nodes forward all of our logs to. This layer will provide a layer of protection in case our ELK-Processor nodes go offline, have an indexing issue or the need for maintenance is in order. I have personally tested this by shutting down my ELK-Processor nodes for 12 hours and then bringing them back online and watching all of the logs start showing up in Kibana with the appropriate time of the events. (I may even decide to move Kibana up into this layer to ensure that it is available if the ELK-Processors are offline)</p>
<p>So let's setup these nodes now. And as assumed there is a script for this too.<br />
So on your ELK-Broker node #1 do the following.</p>
<pre>sudo apt-get install git
cd ~
git clone https://github.com/mrlesmithjr/Logstash_Kibana3
chmod +x Logstash_Kibana3/Cluster/ELK-Broker-Node.sh
sudo ./Logstash_Kibana3/Cluster/ELK-Broker-Node.sh</pre>
<p>Once ELK-Broker node #1 is complete continue onto setting up the second node by running the above again.<br />
Once both ELK-Broker nodes are complete proceed onto setting up the ELK-Processor nodes.</p>
<hr />
<p><strong>ELK-Processor Nodes (elk-processor-1, elk-processor-2):</strong></p>
<p>Now we are ready to set up our <del>ELK frontend nodes</del> ELK-Processor nodes and again I have a script to make this process repeatable and simple. For now we will only be setting up two ELK-Processor nodes; however you can build out as many as you like and use this same script each time for each additional node. Just make sure that every node-name is unique and has a DNS record associated with it.</p>
<p>So to get started all you need to do is run the following on a fresh Ubuntu 12.04LTS/14.04LTS server. And let the script setup your ELK node. Again this script will install Elasticsearch and join the "logstash-cluster" <del>with master capabilities and as a data node</del> as a client node, install Logstash with many different filtering patterns and inputs; as well as join the "logstash-cluster" as a client node (From logstash output - so yes; 2 instances per ELK node will show as clients in the ES cluster) to output all logs to and install the Kibana3 webUI configured to read from the "logstash-cluster". These ELK-Processor nodes will do all of the heavy lifting for logstash processing as well as servicing Kibana requests meanwhile keeping that load off of the ES Master/Data nodes from above (allowing them to do nothing more than churn data).</p>
<pre><del>sudo apt-get install git
cd ~
git clone https://github.com/mrlesmithjr/Logstash_Kibana3
chmod +x ./Logstash_Kibana3/Cluster_Setup/Logstash-ELK-ES-Cluster-client-node.sh
sudo ./Logstash_Kibana3/Cluster_Setup/Logstash-ELK-ES-Cluster-client-node.sh
</del></pre>
<pre>sudo apt-get install git
cd ~
git clone https://github.com/mrlesmithjr/Logstash_Kibana3
chmod +x Logstash_Kibana3/Cluster/ELK-Processor-Node.sh
sudo ./Logstash_Kibana3/Cluster/ELK-Processor-Node.sh</pre>
<p><del>Once this has been completed make sure to go back up at the end of the HAProxy setup and install the logstash instance on each node.</del> Once that has been completed you can begin to test out with only one ELK node or you can build out a few more ELK nodes if you like. I would at least start with two to get the full benefit of this setup.</p>
<p><del><strong>****NOTE</strong></del><br />
<del> If you used different naming for your VIP hostname other than logstash you will need to modify the following file on on each of your ELK Client nodes for the Kibana web interface to connect to ES correctly.</del><br />
<del> You can do that by doing the following and replacing logstash with your viphostname used for your setup...(example myloghostname)</del><br />
<del> Edit /usr/share/nginx/html/kibana/config.js and change http://logstash:9200 to http://yourviphostname:9200</del></p>
<pre><del>sudo nano /usr/share/nginx/html/kibana/config.js</del></pre>
<p><del>Or you can do the following but replace yourviphostname with the actual VIP hostname used for your setup</del></p>
<pre><del>sed -i -e 's|^elasticsearch: "http://logstash:9200",|elasticsearch: "http://yourviphostname:9200",|' /usr/share/nginx/html/kibana/config.js
</del></pre>
<p>Now all that is left to do is configure your network devices to start sending their syslogs to the HAProxy VIP and if your device supports sending via TCP, <strong><em>use it</em></strong>. Why use it? Because you will benefit from the load balancing of the TCP connections and there will not be any lost events (UDP - Best effort, fast!, TCP - Guaranteed, slower; but this type of setup will bring great results!)</p>
<p>Reference the port list below on configuring some of the devices that are pre-configured during the setup.</p>
<hr />
<p><strong>Port List</strong><br />
<em>TCP/514</em> Syslog (Devices supporting TCP)<br />
<em>UDP/514</em> Syslog (Devices that do not support TCP - These are captured on the HAProxy nodes and shipped to logstash using redis)<br />
<em>TCP/1514</em> VMware ESXi<br />
<em>TCP/1515</em> VMware vCenter (Windows install or appliance) (For Windows install use NXLog from below in device setup) (For appliance reference device setup below)<br />
<em>TCP/3515</em> Windows Eventlog (Use NXLog setup from below in device setup)<br />
<em>TCP/3525</em> Windows IIS Logs (Use NXLog setup from below in device setup)</p>
<hr />
<p><strong>Device Setup</strong><br />
For <em>Windows</em> (IIS,Eventlog and VMware vCenter logging) install <a title="http://nxlog.org/" href="http://nxlog.org/" target="_blank">nxlog </a>and use the following nxlog.conf file below to replace everything in C:\Program Files (x86)\nxlog\conf\nxlog.conf<br />
https://gist.github.com/mrlesmithjr/cf212836b9ce162373ed</p>
<p>For <em>VMware vCenter appliance</em> do the following from the appliance console.</p>
<pre>vi /etc/syslog-ng/syslog-ng.conf</pre>
<p>Now add the following to the end of the syslog-ng.conf file</p>
<pre>source vpxd {
       file("/var/log/vmware/vpx/vpxd.log" follow_freq(1) flags(no-parse));
       file("/var/log/vmware/vpx/vpxd-alert.log" follow_freq(1) flags(no-parse));
       file("/var/log/vmware/vpx/vws.log" follow_freq(1) flags(no-parse));
       file("/var/log/vmware/vpx/vmware-vpxd.log" follow_freq(1) flags(no-parse));
       file("/var/log/vmware/vpx/inventoryservice/ds.log" follow_freq(1) flags(no-parse));
};

# Remote Syslog Host
destination remote_syslog {
       tcp("logstash" port (1515));
};
#
# Log vCenter Server vpxd log remotely
log {
        source(vpxd);
        destination(remote_syslog);
};
</pre>
<p>Now restart syslog-ng</p>
<pre>/etc/init.d/syslog restart</pre>
<p>For <em>Linux</em> (Ubuntu, etc.) I prefer rsyslog as it is installed by default on most.</p>
<pre>sudo nano /etc/rsyslog.d/50-default.conf</pre>
<p>Now add the following to the end of this file</p>
<pre>*.* @@logstash</pre>
<p>Note the <em>"@@"</em> this means use TCP; whereas "@" means use UDP.</p>
<hr />
<p>Now that your setup is complete you can browse to the Kibana webUI by using your browser of choice and go <a title="http://logstash/kibana" href="http://logstash/kibana" target="_blank">here</a>.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-07_22-06-43.png"><img class="alignnone size-medium wp-image-2809" src="{{ site.baseurl }}/assets/2014-06-07_22-06-43-300x171.png" alt="2014-06-07_22-06-43" width="300" height="171" /></a></p>
<p>You should see some logs showing up here now but the view is not that great or usable so you will need to start building how you want your dashboard to look. Or you can use some of the dashboards I have created by clicking the load folder at the top right and go to advanced and enter the gist number or url by using the gist url's below (copy and paste the https://url). Once you load the dashboard make sure to save it or it will be gone once you browse away.<br />
Apache <em>https://gist.github.com/mrlesmithjr/32affb2316d38500f7e5</em><br />
Windows IIS <em>https://gist.github.com/mrlesmithjr/4c20dd5ffc79c47474a2</em><br />
Nginx <em>https://gist.github.com/mrlesmithjr/cf8cb356b05765bd764d</em><br />
PFsense Firewall <em>https://gist.github.com/mrlesmithjr/f4c9945e04de3211d076</em><br />
Syslog <em>https://gist.github.com/mrlesmithjr/b0c8f9d8495c8dbefba7</em><br />
VMware <em>https://gist.github.com/mrlesmithjr/3f7c937cbefe83dafc60</em><br />
Windows <em>https://gist.github.com/mrlesmithjr/a9847a369c7d92bbac1d</em></p>
<p>To view your Elasticsearch <a title="http://www.elastichq.org/" href="http://www.elastichq.org/" target="_blank">Elastic HQ</a> plugin go <a title="http://logstash:9200/_plugin/HQ/" href="http://logstash:9200/_plugin/HQ/" target="_blank">here</a>.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-07_22-40-07.png"><img class="alignnone size-medium wp-image-2818" src="{{ site.baseurl }}/assets/2014-06-07_22-40-07-300x171.png" alt="2014-06-07_22-40-07" width="300" height="171" /></a></p>
<p>To view the Elasticsearch <a title="https://github.com/karmi/elasticsearch-paramedic" href="https://github.com/karmi/elasticsearch-paramedic" target="_blank">Paramedic</a> plugin go <a title="http://logstash:9200/_plugin/paramedic/index.html" href="http://logstash:9200/_plugin/paramedic/index.html" target="_blank">here</a>.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-07_22-46-47.png"><img class="alignnone size-medium wp-image-2825" src="{{ site.baseurl }}/assets/2014-06-07_22-46-47-300x171.png" alt="2014-06-07_22-46-47" width="300" height="171" /></a></p>
<p>To view the Elasticsearch <a title="http://mobz.github.io/elasticsearch-head/" href="http://mobz.github.io/elasticsearch-head/" target="_blank">Head</a> plugin go <a title="http://logstash:9200/_plugin/paramedic/index.html" href="http://logstash:9200/_plugin/paramedic/index.html" target="_blank">here</a>.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-07_22-48-38.png"><img class="alignnone size-medium wp-image-2829" src="{{ site.baseurl }}/assets/2014-06-07_22-48-38-300x171.png" alt="2014-06-07_22-48-38" width="300" height="171" /></a></p>
<p>To view the Elasticsearch <a title="http://www.elasticsearch.org/overview/marvel/" href="http://www.elasticsearch.org/overview/marvel/" target="_blank">Marvel</a> plugin go <a title="http://logstash:9200/_plugin/marvel/" href="http://logstash:9200/_plugin/marvel/" target="_blank">here</a>.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-07_22-50-20.png"><img class="alignnone size-medium wp-image-2830" src="{{ site.baseurl }}/assets/2014-06-07_22-50-20-300x171.png" alt="2014-06-07_22-50-20" width="300" height="171" /></a></p>
<p>To view your HAProxy stats go <a title="http://logstash:9090/haproxy?stats" href="http://logstash:9090/haproxy?stats" target="_blank">here</a>. (Login with admin/admin)</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-07_22-56-07.png"><img class="alignnone size-medium wp-image-2838" src="{{ site.baseurl }}/assets/2014-06-07_22-56-07-300x171.png" alt="2014-06-07_22-56-07" width="300" height="171" /></a></p>
<p>So there you have it. A highly available ELK setup which also allows us to scale out extremely easy and is repeatable.</p>
<p>While I have been going through this setup and testing out different components brought to light many other options for HAProxy and the ideas behind this post so stay tuned to more soon. As well as I will be providing a visio drawing of the layout. I am also working on some scripts to setup a proxy (nginx) in front of kibana for ssl password protection to login and to redirect ES queries through the proxy; as well as some scripts to do IPTables firewall configurations to tighten down access into the ES nodes forcing access through the nginx proxy and HAProxy Load Balancers mitigating access directly to an ES node. This will all be in a follow up post very soon.</p>
<hr />
<p>&nbsp;</p>
<p><strong>Follow up posts</strong></p>
<p><a title="Highly Available ELK (Elasticsearch, Logstash and Kibana) Unicast Mode" href="http://everythingshouldbevirtual.com/highly-available-elk-elasticsearch-logstash-kibana-unicast-mode">Setup all ELK components to work in unicast mode instead of mutlicast discovery mode.</a></p>
<p>&nbsp;</p>
<p>Here is a quick screenshot of performance from the marvel plugin just for reference. Only processing about 6GB/Day right now.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/2014-06-26_11-34-18.png"><img class="alignnone size-medium wp-image-2993" src="{{ site.baseurl }}/assets/2014-06-26_11-34-18-300x172.png" alt="2014-06-26_11-34-18" width="300" height="172" /></a></p>
<p>&nbsp;</p>
<p>Here is a drawing which represents this setup.</p>
<p><a href="http://everythingshouldbevirtual.com/wp-content/uploads/2014/06/ELK-Stack-HA.png"><img class="alignnone size-medium wp-image-3021" src="{{ site.baseurl }}/assets/ELK-Stack-HA-300x233.png" alt="ELK-Stack-HA" width="300" height="233" /></a></p>
<p>&nbsp;</p>
<p>If you are in need of an ELK consultant or someone to install and get everything up and running head over <a title="http://monster-solutions.net/2014/07/03/elk-stack-logging-solutions-now-available/" href="http://monster-solutions.net/2014/07/03/elk-stack-logging-solutions-now-available/" target="_blank">here</a>.</p>
<p>Enjoy!</p>
